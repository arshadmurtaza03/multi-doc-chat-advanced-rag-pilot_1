{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3531f933",
   "metadata": {},
   "source": [
    "### Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e748f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install -q langchain langchain-groq langchain-huggingface sentence-transformers faiss-cpu python-dotenv langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a951ec0",
   "metadata": {},
   "source": [
    "### Step 2: Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8169abad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROQ_API_KEY loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"GROQ_API_KEY\"):\n",
    "    raise ValueError(\"GROQ_API_KEY not found in .env file\")\n",
    "else:\n",
    "    print(\"GROQ_API_KEY loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ad03c4",
   "metadata": {},
   "source": [
    "### Step 3: Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e1d604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document(s).\n",
      "First 500 chars: Understanding Agentic AI\n",
      "\n",
      "Agentic AI refers to a new paradigm in artificial intelligence where systems are designed not just to respond to queries or perform specific tasks, but to operate autonomously towards achieving predefined goals. This involves capabilities such as planning, reasoning, executing actions, and continuously adapting to dynamic environments without constant human intervention.\n",
      "\n",
      "Key Characteristics of Agentic AI\n",
      "\n",
      "Agentic AI systems are distinct from traditional AI models due t\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# file path\n",
    "file_path = \"/home/arshad_murtaza/ars_projects/multi-doc-chat-advanced-rag-pilot_1/data/Agentic AI.txt\" \n",
    "\n",
    "loader = TextLoader(file_path, encoding=\"utf8\")\n",
    "documents = loader.load()\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(documents)} document(s).\")\n",
    "print(f\"First 500 chars: {documents[0].page_content[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db906566",
   "metadata": {},
   "source": [
    "### Step 4: Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a3966fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 21\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "text_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total chunks created: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c05288",
   "metadata": {},
   "source": [
    "### Step 5: Initialize HuggingFace Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "170c36c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arshad_murtaza/ars_projects/multi-doc-chat-advanced-rag-pilot_1/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Using 'all-MiniLM-L6-v2' \n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56efa4a",
   "metadata": {},
   "source": [
    "### Step 6: Create Vector Store (FAISS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86d6a854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store created successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Create the vector store\n",
    "vectorstore = FAISS.from_documents(text_chunks, embeddings)\n",
    "\n",
    "\n",
    "print(\"Vector Store created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903e3065",
   "metadata": {},
   "source": [
    "### Step 7: Setup Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85ca816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad02aff",
   "metadata": {},
   "source": [
    "### Step 8: Define Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09dc6354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use ten sentences maximum and keep the answer concise.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a7ad4c",
   "metadata": {},
   "source": [
    "### Step 9: Initialize Groq LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3335c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Initialize Groq Chat Model\n",
    "llm_model = ChatGroq(\n",
    "    model=\"openai/gpt-oss-20b\", \n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44331c48",
   "metadata": {},
   "source": [
    "### Step 10: Build and Run the RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffb4521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic AI is a new paradigm in artificial intelligence that moves beyond simple query‑response or task‑specific behavior. Instead, these systems are designed to act autonomously, setting and pursuing their own goals within a given environment. Key characteristics include self‑directed planning, adaptive learning, and the ability to evaluate progress toward objectives. Understanding Agentic AI involves studying how such systems balance exploration and exploitation while maintaining alignment with human values. Researchers envision a future where Agentic AI can collaborate with humans, manage complex projects, and innovate independently. However, this autonomy also raises challenges in safety, accountability, and ethical governance that must be addressed as the technology matures.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm_model\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "# Invoke the chain\n",
    "response = rag_chain.invoke(\"tell me about Agentic AI\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58234518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
